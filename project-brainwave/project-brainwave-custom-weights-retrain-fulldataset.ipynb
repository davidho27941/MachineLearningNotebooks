{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development with Custom Weights"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to retrain a model with custom weights and fine-tune the model with quantization, then deploy the model running on FPGA. Only Windows is supported. We use TensorFlow and Keras to build our model. We are going to use transfer learning, with ResNet50 as a featurizer. We don't use the last layer of ResNet50 in this case and instead add our own classification layer using Keras.\n",
    "\n",
    "The custom wegiths are trained with ImageNet on ResNet50. We are using a public Top tagging dataset as our training data.\n",
    "\n",
    "Please set up your environment as described in the [quick start](project-brainwave-quickstart.ipynb).\n",
    "\n",
    "This work was performed on the Caltech GPU cluster. The specific server is named imperium-sm.hep.caltech.edu. Paths have been set to work in that environment, but must be altered for your purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15041670550604289821, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 15578061210\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 5647362731204246404\n",
       " physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,sys\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import tables\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "After you train your model in float32, you'll write the weights to a place on disk. We also need a location to store the models that get downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These directories were chosen because they write the data to local disk, which will have the fastest access time\n",
    "# of our various storage options.\n",
    "custom_weights_dir = os.path.expanduser(\"../weights-floatingpoint\")\n",
    "custom_weights_dir_q = os.path.expanduser(\"../weights-quantized\")\n",
    "custom_weights_dir_tl = os.path.expanduser(\"../weights-transferlearning-floatingpoint\")\n",
    "saved_model_dir = os.path.expanduser(\"../models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "Load the files we are going to use for training and testing. The public Top dataset consists of image formatted data, but our data has been preprocessed into a raw form.\n",
    "\n",
    "At the time of writing, the files in question are located at `/data/shared/dwerran/converted`. They are stored in the HDF5 format, and must be accessed via the `tables` module. The two sub-datasets we're interested in are `/img-pt` and `/labels`, corresponding to the images and lables respectively. Each dataset contains 50000 images, and there are about 30 datasets. As before, this storage location was chosen to maximize data bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import normalize_and_rgb, image_with_label, count_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train_events = 1211000\n",
      "n_test_events = 404000\n",
      "n_val_events = 404000\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "datadir = \"../data/\"\n",
    "n_train_file = 25\n",
    "n_test_file = 9\n",
    "n_val_file = 9\n",
    "\n",
    "train_files = glob.glob(os.path.join(datadir, 'train_file_*'))\n",
    "test_files = glob.glob(os.path.join(datadir, 'test/test_file_*'))\n",
    "val_files = glob.glob(os.path.join(datadir, 'val_file_*'))\n",
    "train_files = train_files[:n_train_file]\n",
    "test_files = test_files[:n_test_file]\n",
    "val_files = test_files[:n_val_file]\n",
    "\n",
    "n_train_events = count_events(train_files)\n",
    "n_test_events = count_events(test_files)\n",
    "n_val_events = count_events(val_files)\n",
    "\n",
    "print(\"n_train_events =\", n_train_events)\n",
    "print(\"n_test_events =\", n_test_events)\n",
    "print(\"n_val_events =\", n_val_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "a, b = image_with_label(train_files[0],0,20000)\n",
    "new_a = np.swapaxes(a[:,:,:,0],0,2)\n",
    "new_a = np.swapaxes(new_a,0,1)\n",
    "c = np.dot(new_a,b[:,0])\n",
    "d = np.dot(new_a,b[:,1])\n",
    "%matplotlib inline\n",
    "#mpl.use('agg')\n",
    "\n",
    "width = 64\n",
    "height = 64\n",
    "fontsize = 120\n",
    "\n",
    "plt.figure(figsize=(width,height))\n",
    "ax = plt.subplot() \n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()): label.set_fontsize(fontsize)\n",
    "plt.imshow(c, norm=mpl.colors.LogNorm(), origin='lower', interpolation='nearest',label='top')\n",
    "cbar = plt.colorbar(shrink=0.82)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "cbar.set_label(r'$p_T$', fontsize=fontsize)\n",
    "plt.xlabel(r'$i\\eta$', fontsize=fontsize)\n",
    "plt.ylabel(r'$i\\phi$', fontsize=fontsize)\n",
    "plt.savefig('top.pdf')\n",
    "\n",
    "plt.figure(figsize=(width,height))\n",
    "ax = plt.subplot() \n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()): label.set_fontsize(fontsize)\n",
    "plt.imshow(d, norm=mpl.colors.LogNorm(), origin='lower', interpolation='nearest',label='QCD')\n",
    "cbar = plt.colorbar(shrink=0.82)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "cbar.set_label(r'$p_T$', fontsize=fontsize)\n",
    "plt.xlabel(r'$i\\eta$', fontsize=fontsize)\n",
    "plt.ylabel(r'$i\\phi$', fontsize=fontsize)\n",
    "plt.savefig('QCD.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Model\n",
    "We use ResNet50 for the featuirzer and build our own classifier using Keras layers. We train the featurizer and the classifier as one model. The weights trained on ImageNet are used as the starting point for the retraining of our featurizer. The weights are loaded from tensorflow checkpoint files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before passing image dataset to the ResNet50 featurizer, we need to preprocess the input file to get it into the form expected by ResNet50. ResNet50 expects float tensors representing the images in BGR, channel last order. Given that our images are greyscale, this isn't relevant to us, as we will simply be copying the data in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocess_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Keras layer APIs to construct the classifier. Because we're using the tensorflow backend, we can train this classifier in one session with our Resnet50 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import construct_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now every component of the model is defined, we can construct the model. Constructing the model with the project brainwave models is two steps - first we import the graph definition, then we restore the weights of the model into a tensorflow session. Because the quantized graph defintion and the float32 graph defintion share the same node names in the graph definitions, we can initally train the weights in float32, and then reload them with the quantized operations (which take longer) to fine-tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import construct_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "First we train the model with custom weights but without quantization. Training is done with native float precision (32-bit floats). We load the traing data set and batch the training with 10 epochs. When the performance reaches desired level or starts decredation, we stop the training iteration and save the weights as tensorflow checkpoint files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import chunks, train_model, test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training currently leverages a hack to work around some apparent limits in the BW API. I have attempted to specify a custom weights directory when calling the `Resnet50` function in `construct_model()` above in the same way it is specified for `Quantized_Resnet50`. However, this throws an error, and since there is no API documentation yet, the way I'm working around it is rewriting our trained weights to the saved model directory. I will be reaching out to the team on this topic to see if they have a better suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in restore_weights\n",
      "checkpoint directory: ../models/rn50/1.1.3\n",
      "lastest checkpoint: ../models/rn50/1.1.3/resnet50_bw\n",
      "INFO:tensorflow:Restoring parameters from ../models/rn50/1.1.3/resnet50_bw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18940it [1:11:34,  4.41it/s]                           \n",
      "  0%|          | 0/6313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss =  0.224\n",
      "Training Accuracy: 0.909 , Area under ROC curve: 0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6319it [07:51, 13.40it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 val_loss =  0.188\n",
      "Validation Accuracy: 0.924 , Area under ROC curve: 0.971\n",
      "new best model\n",
      "in restore_weights\n",
      "checkpoint directory: ../models/rn50/1.1.3\n",
      "lastest checkpoint: ../models/rn50/1.1.3/resnet50_bw\n",
      "INFO:tensorflow:Restoring parameters from ../models/rn50/1.1.3/resnet50_bw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 4647/6313 [05:44<01:49, 15.27it/s]  "
     ]
    }
   ],
   "source": [
    "# Launch the training\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "\n",
    "num_epoch_train = 1\n",
    "\n",
    "with sess.as_default():\n",
    "    in_images, image_tensors, features, preds, featurizer, classifier = construct_model(quantized=False, saved_model_dir=saved_model_dir, is_training=True)\n",
    "    saver = tf.train.Saver(max_to_keep = 100)\n",
    "    loss_over_epoch, accuracy_over_epoch, auc_over_epoch, val_loss_over_epoch, val_accuracy_over_epoch, val_auc_over_epoch = \\\n",
    "        train_model(preds, in_images, train_files, val_files, is_retrain=False, train_epoch=num_epoch_train, \n",
    "                    classifier=classifier,\n",
    "                    saver=saver, checkpoint_path=custom_weights_dir) \n",
    "    _, _, features, preds, featurizer, classifier = construct_model(quantized=False, saved_model_dir=saved_model_dir, is_training=False)\n",
    "    loss, accuracy, auc, preds_test, test_labels = test_model(preds, in_images, test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Test Model\n",
    "Alternatively, we can load a pre-trained model for testing. Here, we re-load the weights saved on disk and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a trained model\n",
      "in restore_weights\n",
      "checkpoint directory: ../weights-floatingpoint\n",
      "lastest checkpoint: ../weights-floatingpoint/resnet50_bw-6\n",
      "INFO:tensorflow:Restoring parameters from ../weights-floatingpoint/resnet50_bw-6\n",
      "loading classifier weights from ../weights-floatingpoint/class_weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6319it [07:41, 13.69it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss =  7.696\n",
      "Test Accuracy: 0.511 , Area under ROC curve: 0.509\n",
      "Accuracy: 0.5110767326732228 , Area under ROC curve: 0.5087705024964732\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "\n",
    "with sess.as_default():\n",
    "    print(\"Loading a trained model\")\n",
    "    in_images, image_tensors, features, preds, featurizer, classifier = construct_model(quantized=False, saved_model_dir=saved_model_dir, starting_weights_directory=custom_weights_dir, is_training=False)\n",
    "    loss, accuracy, auc, preds_test, test_labels = test_model(preds, in_images, test_files)\n",
    "    print(\"Accuracy:\", accuracy, \", Area under ROC curve:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Quantized Model\n",
    "After training, we evaluate the trained model's accuracy on test dataset with quantization. So that we know the model's performance if it is deployed on the FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "\n",
    "with sess.as_default():\n",
    "    print(\"Testing trained model with quantization\")\n",
    "    in_images_q, image_tensors_q, features_q, preds_q, quantized_featurizer, classifier = construct_model(quantized=True, saved_model_dir=saved_model_dir, starting_weights_directory=custom_weights_dir)\n",
    "    loss_q, accuracy_q, auc_q, preds_test_q, test_labels_q = test_model(preds_q, in_images_q, test_files)\n",
    "    print(\"Accuracy:\", accuracy_q, \", Area under ROC curve:\", auc_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune Quantized Model\n",
    "Sometimes, the model's accuracy can drop significantly after quantization. In those cases, we need to retrain the model enabled with quantization to get better model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch_finetune = 5\n",
    "\n",
    "with sess.as_default():\n",
    "    print(\"Fine-tuning model with quantization\")        \n",
    "    saver = tf.train.Saver(max_to_keep = 100)\n",
    "    \n",
    "    loss_over_epoch_ft, accuracy_over_epoch_ft, auc_over_epoch_ft, val_loss_over_epoch_ft, val_accuracy_over_epoch_ft, val_auc_over_epoch_ft = \\\n",
    "        train_model(preds_q, in_images_q, train_files, val_files, is_retrain=True, train_epoch=num_epoch_finetune, \n",
    "                    classifier=classifier,\n",
    "                    saver=saver, checkpoint_path=custom_weights_dir_q) \n",
    "    loss_ft, accuracy_ft, auc_ft, preds_test_ft, test_labels_ft = test_model(preds_q, in_images_q, test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Test Quantized Model\n",
    "Alternatively, we can load a pre-trained quantized model for testing. Here, we re-load the weights saved on disk and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "with sess.as_default():\n",
    "    print(\"Re-load fine-tuned model with quantization\")   \n",
    "    in_images_q, image_tensors_q, features_q, preds_q, quantized_featurizer, classifier = construct_model(quantized=True, saved_model_dir=saved_model_dir, starting_weights_directory=custom_weights_dir_q)\n",
    "    loss_ft, accuracy_ft, auc_ft, preds_test_ft, test_labels_ft = test_model(preds_q, in_images_q, test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "\n",
    "num_epoch_train = 20\n",
    "\n",
    "with sess.as_default():\n",
    "    in_images, image_tensors, features, preds, featurizer, classifier = construct_model(quantized=False, is_frozen=True, saved_model_dir=saved_model_dir)\n",
    "    saver = tf.train.Saver(max_to_keep = 100)\n",
    "    loss_over_epoch_tl, accuracy_over_epoch_tl, auc_over_epoch_tl, val_loss_over_epoch_tl, val_accuracy_over_epoch_tl, val_auc_over_epoch_tl = \\\n",
    "        train_model(preds, in_images, train_files, val_files, is_retrain=True, train_epoch=num_epoch_train, \n",
    "                    classifier=classifier,\n",
    "                    saver=saver, checkpoint_path=custom_weights_dir_tl) \n",
    "    loss_tl, accuracy_tl, auc_tl, preds_test_tl, test_labels_tl = test_model(preds, in_images, test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Test Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a training\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "\n",
    "with sess.as_default():\n",
    "    print(\"Loading a trained model\")\n",
    "    in_images, image_tensors, features, preds, featurizer, classifier = construct_model(quantized=False, is_frozen=True, saved_model_dir=saved_model_dir)\n",
    "    print(\"loading classifier weights from\", custom_weights_dir_tl+'/class_weights.h5')\n",
    "    classifier.load_weights(custom_weights_dir_tl+'/class_weights.h5')\n",
    "    loss_tl, accuracy_tl, auc_tl, preds_test_tl, test_labels_tl = test_model(preds, in_images, test_files)\n",
    "    print(\"Accuracy:\", accuracy_tl, \", Area under ROC curve:\", auc_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Test Quantized Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "\n",
    "with sess.as_default():\n",
    "    print(\"Re-load fine-tuned model with quantization\")   \n",
    "    in_images_q, image_tensors_q, features_q, preds_q, quantized_featurizer, classifier = construct_model(quantized=True, is_frozen=True, saved_model_dir=saved_model_dir)\n",
    "    print(\"loading classifier weights from\", custom_weights_dir_tl+'/class_weights.h5')\n",
    "    classifier.load_weights(custom_weights_dir_tl+'/class_weights.h5')\n",
    "    loss_tl_q, accuracy_tl_q, auc_tl_q, preds_test_tl_q, test_labels_tl_q = test_model(preds_q, in_images_q, test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr_test, tpr_test, thresholds = metrics.roc_curve(test_labels[:,0],preds_test[:,0])\n",
    "fpr_test_q, tpr_test_q, thresholds_q = metrics.roc_curve(test_labels_q[:,0],preds_test_q[:,0])\n",
    "fpr_test_ft, tpr_test_ft, thresholds_ft = metrics.roc_curve(test_labels_ft[:,0],preds_test_ft[:,0])\n",
    "fpr_test_tl, tpr_test_tl, thresholds_tl = metrics.roc_curve(test_labels_tl[:,0],preds_test_tl[:,0])\n",
    "fpr_test_tl_q, tpr_test_tl_q, thresholds_tl_q = metrics.roc_curve(test_labels_tl_q[:,0],preds_test_tl_q[:,0])\n",
    "\n",
    "auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "auc_test_q = metrics.auc(fpr_test_q, tpr_test_q)\n",
    "auc_test_ft = metrics.auc(fpr_test_ft, tpr_test_ft)\n",
    "auc_test_tl = metrics.auc(fpr_test_tl, tpr_test_tl)\n",
    "auc_test_tl_q = metrics.auc(fpr_test_tl_q, tpr_test_tl_q)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(tpr_test,fpr_test,label='Custom weights, AUC = %.2f%%'%(auc_test*100.))\n",
    "plt.plot(tpr_test_q,fpr_test_q,label='Custom weights, quantized, AUC = %.2f%%'%(auc_test_q*100.))\n",
    "#plt.plot(tpr_test_ft,fpr_test_ft,label='Custom weights, quantized, fine-tuned, AUC = %.2f%%'%(auc_test_ft*100.))\n",
    "plt.plot(tpr_test_tl,fpr_test_tl,label='Tranfer learning, AUC = %.2f%%'%(auc_test_tl*100.))\n",
    "plt.plot(tpr_test_tl_q,fpr_test_tl_q,label='Tranfer learning, quantized, AUC = %.2f%%'%(auc_test_tl_q*100.))\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"Signal efficiency\")\n",
    "plt.ylabel(\"Background efficiency\")\n",
    "plt.ylim(0.00001,1)\n",
    "plt.xlim(0,1)\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('ROC_ft.pdf')\n",
    "\n",
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx\n",
    "\n",
    "idx = find_nearest(tpr_test,0.3)\n",
    "idx_q = find_nearest(tpr_test_q,0.3)\n",
    "idx_ft = find_nearest(tpr_test_ft,0.3)\n",
    "idx_tl = find_nearest(tpr_test_tl,0.3)\n",
    "idx_tl_q = find_nearest(tpr_test_tl_q,0.3)\n",
    "\n",
    "print (loss, accuracy, auc_test, tpr_test[idx], 1./fpr_test[idx])\n",
    "print (loss_q, accuracy_q, auc_test_q, tpr_test_q[idx_q], 1./fpr_test_q[idx_q])\n",
    "print (loss_ft, accuracy_ft, auc_test_ft, tpr_test_ft[idx_ft], 1./fpr_test_ft[idx_ft])\n",
    "print (loss_tl, accuracy_tl, auc_test_tl, tpr_test_tl[idx_tl], 1./fpr_test_tl[idx_tl])\n",
    "print (loss_tl_q, accuracy_tl_q, auc_test_tl_q, tpr_test_tl_q[idx_tl_q], 1./fpr_test_tl_q[idx_tl_q])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "License for plot_confusion_matrix:\n",
    "\n",
    "New BSD License\n",
    "\n",
    "Copyright (c) 2007-2018 The scikit-learn developers.\n",
    "All rights reserved.\n",
    "\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without\n",
    "modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "  a. Redistributions of source code must retain the above copyright notice,\n",
    "     this list of conditions and the following disclaimer.\n",
    "  b. Redistributions in binary form must reproduce the above copyright\n",
    "     notice, this list of conditions and the following disclaimer in the\n",
    "     documentation and/or other materials provided with the distribution.\n",
    "  c. Neither the name of the Scikit-learn Developers  nor the names of\n",
    "     its contributors may be used to endorse or promote products\n",
    "     derived from this software without specific prior written\n",
    "     permission. \n",
    "\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE FOR\n",
    "ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n",
    "LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n",
    "OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH\n",
    "DAMAGE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "coverste"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

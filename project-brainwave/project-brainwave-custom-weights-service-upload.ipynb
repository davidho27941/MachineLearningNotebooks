{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brainwave Service Upload\n",
    "This Notebook is intended to simplify the training / upload process by splitting the two steps into two separate notebooks. In particular, this Notebook is for uploading a previously-trained model to the cloud, and doesn't contain any training code. It does have some sanity check code to ensure you're loading in the right model, before actually uploading it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though these first few cells are repeated in the training Notebooks, it is necessary here since we still must set up the environment to load the model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2678279902009604215, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 15578061210\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 5302330717599581887\n",
       " physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,sys\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import tables\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These directories were chosen because they write the data to local disk, which will have the fastest access time\n",
    "# of our various storage options.\n",
    "custom_weights_dir = os.path.expanduser(\"../weights-floatingpoint\")\n",
    "custom_weights_dir_q = os.path.expanduser(\"../weights-quantized\")\n",
    "custom_weights_dir_tl = os.path.expanduser(\"../weights-transferlearning-floatingpoint\")\n",
    "saved_model_dir = os.path.expanduser(\"../models\")\n",
    "results_dir = os.path.expanduser(\"../results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "Load the files we are going to use for training and testing. The public Top dataset consists of image formatted data, but our data has been preprocessed into a raw form. You will need to edit the paths as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import normalize_and_rgb, image_with_label, count_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train_events = 1211000\n",
      "n_test_events = 404000\n",
      "n_val_events = 404000\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "datadir = \"../data/\"\n",
    "n_train_file = 25\n",
    "n_test_file = 9\n",
    "n_val_file = 9\n",
    "\n",
    "train_files = glob.glob(os.path.join(datadir, 'train_file_*'))\n",
    "test_files = glob.glob(os.path.join(datadir, 'test/test_file_*'))\n",
    "val_files = glob.glob(os.path.join(datadir, 'val_file_*'))\n",
    "train_files = train_files[:n_train_file]\n",
    "test_files = test_files[:n_test_file]\n",
    "val_files = test_files[:n_val_file]\n",
    "\n",
    "n_train_events = count_events(train_files)\n",
    "n_test_events = count_events(test_files)\n",
    "n_val_events = count_events(val_files)\n",
    "\n",
    "print(\"n_train_events =\", n_train_events)\n",
    "print(\"n_test_events =\", n_test_events)\n",
    "print(\"n_val_events =\", n_val_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Model\n",
    "We use ResNet50 for the featuirzer and build our own classifier using Keras layers. We train the featurizer and the classifier as one model. The weights trained on ImageNet are used as the starting point for the retraining of our featurizer. The weights are loaded from tensorflow checkpoint files.\n",
    "\n",
    "Before passing image dataset to the ResNet50 featurizer, we need to preprocess the input file to get it into the form expected by ResNet50. ResNet50 expects float tensors representing the images in BGR, channel last order. Given that our images are greyscale, this isn't relevant to us, as we will simply be copying the data in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocess_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Keras layer APIs to construct the classifier. Because we're using the tensorflow backend, we can train this classifier in one session with our Resnet50 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import construct_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now every component of the model is defined, we can construct the model. Constructing the model with the project brainwave models is two steps - first we import the graph definition, then we restore the weights of the model into a tensorflow session. Because the quantized graph defintion and the float32 graph defintion share the same node names in the graph definitions, we can initally train the weights in float32, and then reload them with the quantized operations (which take longer) to fine-tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import construct_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load And Check The Model\n",
    "If you already have a trained up, quantized model and don't want to train it any further before uploading it to the Azure server, run this cell. It will load the model and its weights into ram without applying any gradient descents. It will then perform a quick sanity check to ensure the loaded model is the one expected by passing the test images through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing trained model with quantization\n",
      "in restore_weights\n",
      "checkpoint directory: ../weights-quantized\n",
      "lastest checkpoint: ../weights-quantized/resnet50_bw_best\n",
      "INFO:tensorflow:Restoring parameters from ../weights-quantized/resnet50_bw_best\n",
      "loading classifier weights from ../weights-quantized/class_weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [04:40<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss =  0.487\n",
      "Test Accuracy: 0.685 , Area under ROC curve: 0.816\n",
      "Accuracy: 0.6853200000000016 , Area under ROC curve: 0.8164971537971497\n"
     ]
    }
   ],
   "source": [
    "from utils import chunks, test_model\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "\n",
    "with sess.as_default():\n",
    "    print(\"Testing trained model with quantization\")\n",
    "    in_images, image_tensors, features, preds, quantized_featurizer, classifier = construct_model(quantized=True, saved_model_dir=saved_model_dir, starting_weights_directory=custom_weights_dir_q, is_training=False)\n",
    "    loss, accuracy, auc, preds_test, test_labels = test_model(preds, in_images, test_files[:1])\n",
    "    print(\"Accuracy:\", accuracy, \", Area under ROC curve:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just Load The Model\n",
    "If you already have a trained up, quantized model and don't want to train it any further before uploading it to the Azure server, run this cell. It will load the model and its weights into ram without applying any gradient descents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading quantized model\n",
      "in restore_weights\n",
      "checkpoint directory: ../weights-floatingpoint\n",
      "lastest checkpoint: ../weights-floatingpoint/resnet50_bw\n",
      "INFO:tensorflow:Restoring parameters from ../weights-floatingpoint/resnet50_bw\n",
      "loading classifier weights from ../weights-floatingpoint/class_weights.h5\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "\n",
    "with sess.as_default():\n",
    "    print(\"Loading quantized model\")\n",
    "    in_images, image_tensors, features, preds, quantized_featurizer, classifier = construct_model(quantized=True, saved_model_dir=saved_model_dir, starting_weights_directory=custom_weights_dir_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service Definition\n",
    "Like in the QuickStart notebook our service definition pipeline consists of three stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 0 variables.\n",
      "Converted 0 variables to const ops.\n",
      "in restore_weights\n",
      "checkpoint directory: ../weights-quantized\n",
      "lastest checkpoint: ../weights-quantized/resnet50_bw_best\n",
      "INFO:tensorflow:Restoring parameters from ../weights-quantized/resnet50_bw_best\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "Converted 4 variables to const ops.\n",
      "../models/model_def.zip\n"
     ]
    }
   ],
   "source": [
    "from azureml.contrib.brainwave.pipeline import ModelDefinition, TensorflowStage, BrainWaveStage\n",
    "\n",
    "model_def_path = os.path.join(saved_model_dir, 'model_def.zip')\n",
    "\n",
    "model_def = ModelDefinition()\n",
    "model_def.pipeline.append(TensorflowStage(sess, in_images, image_tensors))\n",
    "model_def.pipeline.append(BrainWaveStage(sess, quantized_featurizer))\n",
    "model_def.pipeline.append(TensorflowStage(sess, features, preds))\n",
    "model_def.save(model_def_path)\n",
    "print(model_def_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy\n",
    "Go to our GitHub repo \"docs\" folder to learn how to create a Model Management Account and find the required information below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/dwerran/machinelearningnotebooks/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time the code below runs it will create a new service running your model. If you want to change the model you can make changes above in this notebook and save a new service definition. Then this code will update the running service in place to run the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model top-transfer-resnet50-model\n",
      "Creating image\n",
      "Image creation operation finished for image modelbuild-service:20, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running.....................................................\n",
      "SucceededFPGA service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "from azureml.core.image import Image\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.contrib.brainwave import BrainwaveWebservice, BrainwaveImage\n",
    "from azureml.exceptions import WebserviceException\n",
    "\n",
    "model_name = \"top-transfer-resnet50-model\"\n",
    "image_name = \"top-transfer-resnet50-image\"\n",
    "service_name = \"modelbuild-service\"\n",
    "\n",
    "registered_model = Model.register(ws, model_def_path, model_name)\n",
    "\n",
    "image_config = BrainwaveImage.image_configuration()\n",
    "deployment_config = BrainwaveWebservice.deploy_configuration()\n",
    "    \n",
    "try:\n",
    "    service = Webservice(ws, service_name)\n",
    "    service.delete()\n",
    "    service = Webservice.deploy_from_model(ws, service_name, [registered_model], image_config, deployment_config)\n",
    "    service.wait_for_deployment(True)\n",
    "except WebserviceException:\n",
    "    service = Webservice.deploy_from_model(ws, service_name, [registered_model], image_config, deployment_config)\n",
    "    service.wait_for_deployment(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The service is now running in Azure and ready to serve requests. We can check the address and port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.168.151.218:80\n"
     ]
    }
   ],
   "source": [
    "print(service.ip_address + ':' + str(service.port))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client\n",
    "There is a simple test client at amlrealtimeai.PredictionClient which can be used for testing. We'll use this client to score an image with our new service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.brainwave.client import PredictionClient\n",
    "client = PredictionClient(service.ip_address, service.port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request\n",
    "Let's see how our service does on a few images. It may get a few wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9008 AUC: 0.9795795474910393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from utils import chunks\n",
    "\n",
    "test_files = test_files[:1]  # For now...\n",
    "\n",
    "chunk_size = 1  # Brainwave only processes one request at a time\n",
    "n_test_events = count_events(test_files)\n",
    "chunk_num = int(n_test_events/chunk_size)+1\n",
    "\n",
    "correct = 0\n",
    "y_true = np.array([])\n",
    "y_pred = np.array([])\n",
    "\n",
    "for img_chunk, label_chunk, real_chunk_size in tqdm(chunks(test_files, chunk_size), total=chunk_num):\n",
    "    results = client.score_numpy_array(img_chunk)\n",
    "    if (results[0][0] > results[0][1]) == label_chunk[0][0]:\n",
    "        correct += 1\n",
    "        \n",
    "    y_true = np.append(y_true, label_chunk[0][0])  # Convert from one-hot to true/false\n",
    "    y_pred = np.append(y_pred, results[0][0])\n",
    "\n",
    "accuracy = correct / n_test_events\n",
    "auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy, \"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-20-98df99e10690>, line 84)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-98df99e10690>\"\u001b[0;36m, line \u001b[0;32m84\u001b[0m\n\u001b[0;31m    print (\"Brainwave:accuracy_b, auc_test_b, tpr_test_b[idx_b], 1./fpr_test_b[idx_b])\u001b[0m\n\u001b[0m                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "results_dir = os.path.expanduser(\"../results\")\n",
    "\n",
    "# Save the results of the previous test.\n",
    "# Provide the result saving directory, the prefix (see below), the label np array and the pred np array.\n",
    "# It also expects a strict naming paradigm:\n",
    "#   Non-quantized testing should be prefixed 't'\n",
    "#   Quantized testing before fine-tuning should be prefixed 'q'\n",
    "#   Quantized testing after fine-tuning should be prefixed 'ft'\n",
    "#   Quantized testing on Brainwave should be prefixed 'b'\n",
    "def save_results(results_dir, prefix, accuracy, labels, preds):\n",
    "    import numpy as np\n",
    "    \n",
    "    np.save(results_dir + \"/\" + prefix + \"_accuracy.npy\", accuracy)\n",
    "    np.save(results_dir + \"/\" + prefix + \"_labels.npy\", labels)\n",
    "    np.save(results_dir + \"/\" + prefix + \"_preds.npy\", preds)\n",
    "    \n",
    "# Once results have been compiled, use this function to plot them.\n",
    "# It expects all the files to be there at runtime, so if they haven't yet been generated,\n",
    "# comment out the relevant lines.\n",
    "def plot_results(results_dir):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Load the labels and results into memory.\n",
    "#     accuracy_t     = np.load(results_dir + \"/t_accuracy.npy\")\n",
    "#     test_labels_t  = np.load(results_dir + \"/t_labels.npy\")\n",
    "#     test_preds_t   = np.load(results_dir + \"/t_preds.npy\")\n",
    "#     accuracy_q     = np.load(results_dir + \"/q_accuracy.npy\")\n",
    "#     test_labels_q  = np.load(results_dir + \"/q_labels.npy\")\n",
    "#     test_preds_q   = np.load(results_dir + \"/q_preds.npy\")\n",
    "#     accuracy_ft     = np.load(results_dir + \"/ft_accuracy.npy\")\n",
    "#     test_labels_ft = np.load(results_dir + \"/ft_labels.npy\")\n",
    "#     test_preds_ft  = np.load(results_dir + \"/ft_preds.npy\")\n",
    "    accuracy_b     = np.load(results_dir + \"/b_accuracy.npy\")\n",
    "    test_labels_b  = np.load(results_dir + \"/b_labels.npy\")\n",
    "    test_preds_b   = np.load(results_dir + \"/b_preds.npy\")\n",
    "    \n",
    "    # Determine the ROC curve for each of the tests. \n",
    "    # [:,0] will convert the labels from one-hot to binary.\n",
    "#     fpr_test_t, tpr_test_t, thresholds      = metrics.roc_curve(test_labels_t[:,0],  test_preds_t[:,0])\n",
    "#     fpr_test_q, tpr_test_q, thresholds_q    = metrics.roc_curve(test_labels_q[:,0],  test_preds_q[:,0])\n",
    "#     fpr_test_ft, tpr_test_ft, thresholds_ft = metrics.roc_curve(test_labels_ft[:,0], test_preds_ft[:,0])\n",
    "    # We've already turned the labels into binary for the Brainwave pass\n",
    "    fpr_test_b, tpr_test_b, thresholds_b    = metrics.roc_curve(test_labels_b,  test_preds_b)\n",
    "    \n",
    "    # Use the data we just generated to determine the area under the ROC curve.\n",
    "#     auc_test    = metrics.auc(fpr_test_t, tpr_test_t)\n",
    "#     auc_test_q  = metrics.auc(fpr_test_q, tpr_test_q)\n",
    "#     auc_test_ft = metrics.auc(fpr_test_ft, tpr_test_ft)\n",
    "    auc_test_b  = metrics.auc(fpr_test_b, tpr_test_b)\n",
    "\n",
    "    # Plot the ROCs, labeling with the AUCs.\n",
    "#     %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(7,5))\n",
    "#     plt.plot(tpr_test_t,    fpr_test_t,    label='Custom weights, AUC = %.2f%%'%(auc_test*100.))\n",
    "#     plt.plot(tpr_test_q,  fpr_test_q,  label='Custom weights, quantized, AUC = %.2f%%'%(auc_test_q*100.))\n",
    "#     plt.plot(tpr_test_ft, fpr_test_ft, label='Custom weights, quantized, fine-tuned, AUC = %.2f%%'%(auc_test_ft*100.))\n",
    "    plt.plot(tpr_test_b,  fpr_test_b,  label='Custom weights, Brainwave, AUC = %.2f%%'%(auc_test_b*100.))\n",
    "    \n",
    "    plt.semilogy()\n",
    "    plt.xlabel(\"Signal efficiency\")\n",
    "    plt.ylabel(\"Background efficiency\")\n",
    "    plt.ylim(0.00001,1)\n",
    "    plt.xlim(0,1)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.savefig('ROC_ft.pdf')\n",
    "\n",
    "    # Find the true positive rate of 30% and 1 over the false positive rate at tpr = 30%.\n",
    "    def find_nearest(array,value):\n",
    "        idx = (np.abs(array-value)).argmin()\n",
    "        return idx\n",
    "\n",
    "#     idx_t    = find_nearest(tpr_test_t,0.3)\n",
    "#     idx_q  = find_nearest(tpr_test_q,0.3)\n",
    "#     idx_ft = find_nearest(tpr_test_ft,0.3)\n",
    "    idx_b  = find_nearest(tpr_test_b,0.3)\n",
    "    \n",
    "#     print (\"Custom weights:\", loss_t, accuracy_t, auc_test_t, tpr_test_t[idx_t], 1./fpr_test_t[idx_t])\n",
    "#     print (\"Quantized:\", loss_q, accuracy_q, auc_test_q, tpr_test_q[idx_q], 1./fpr_test_q[idx_q])\n",
    "#     print (\"loss_ft, accuracy_ft, auc_test_ft, tpr_test_ft[idx_ft], 1./fpr_test_ft[idx_ft])\n",
    "    print (\"Brainwave:\", accuracy_b, auc_test_b, tpr_test_b[idx_b], 1./fpr_test_b[idx_b])\n",
    "\n",
    "save_results(results_dir, 'b', accuracy, y_true, y_pred)\n",
    "plot_results(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Run the cell below to delete your service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
